# ✅ 混合模型配置完成 - 问题已解决

## 🎯 问题总结

### 之前的问题
使用纯 QVQ-72B-Preview 模型时遇到 JSON 解析错误：

```
Error: Invalid JSON response from AI model: Unexpected token 'T', "To complet"... is not valid JSON
```

**原因**: QVQ-72B-Preview 是推理模型，会输出思维链（CoT）文本而不是结构化 JSON，导致 Midscene 的规划模块（`llm-planning.ts`）无法解析。

---

## ✅ 解决方案：混合模型配置

采用**混合策略**，为不同任务使用最适合的模型：

### 当前配置

```bash
# 主模型和规划任务：Qwen2-VL-72B-Instruct
# - 支持 JSON 结构化输出
# - 兼容 aiAction() 自动规划
MIDSCENE_MODEL_NAME=Qwen/Qwen2-VL-72B-Instruct
MIDSCENE_PLANNING_MODEL_NAME=Qwen/Qwen2-VL-72B-Instruct

# 视觉问答任务：QVQ-72B-Preview
# - 强大的视觉推理能力
# - 更好的元素理解
MIDSCENE_VQA_MODEL_NAME=Qwen/QVQ-72B-Preview

# 元素定位任务：QVQ-72B-Preview
# - 精准的视觉定位
# - 强推理能力
MIDSCENE_GROUNDING_MODEL_NAME=Qwen/QVQ-72B-Preview
```

### 配置优势

| 任务类型 | 使用模型 | 优势 |
|---------|---------|------|
| **规划任务** | Qwen2-VL-72B-Instruct | ✅ 支持 JSON 输出<br>✅ 兼容 `aiAction()` |
| **视觉问答** | QVQ-72B-Preview | ✅ 强大推理能力<br>✅ 准确理解页面 |
| **元素定位** | QVQ-72B-Preview | ✅ 精准视觉定位<br>✅ 容错能力强 |

---

## 🚀 服务状态

### 当前运行信息

- ✅ Playground 前端: http://localhost:3000
- ✅ 后端服务: http://localhost:5870
- ✅ Server ID: `35df0616-b435-4489-840e-87f198dbd24d`
- ✅ 配置文件: `/Users/sunshunda/Desktop/browser/auto_test/.env`
- ✅ 浏览器模式: 非 Headless（可见）
- ✅ 默认页面: https://www.baidu.com

---

## 📝 测试指南

### 方式 1：使用简单指令（推荐）

打开 http://localhost:3000，依次输入：

#### 步骤 1：输入搜索词
```
在搜索框输入"数字浙江"
```

#### 步骤 2：点击搜索
```
点击"百度一下"按钮
```

#### 步骤 3：打开百科
```
点击搜索结果中的"数字浙江 百度百科"链接
```

#### 步骤 4：滚动查找
```
向下滚动500像素
```
（重复 2-3 次，直到看到"统一社会信用代码"）

#### 步骤 5：提取数据
```
提取"统一社会信用代码"的值，返回 JSON: {"creditCode": "代码"}
```

### 方式 2：使用复杂指令（现在支持）

现在可以使用**复杂的一句话指令**了：

```
在百度搜索"数字浙江"，点击百度一下，然后点击搜索结果中的百度百科链接，滚动查找"统一社会信用代码"，提取其值
```

**为什么现在可以了？**
- ✅ 规划模块使用 Qwen2-VL，支持 JSON 输出
- ✅ 视觉任务使用 QVQ，识别能力更强
- ✅ 结合了两个模型的优势

---

## 🔍 预期结果

### 成功标志

1. ✅ **不再出现 JSON 解析错误**
2. ✅ 能找到"百度一下"按钮（之前 Qwen3-VL 找不到）
3. ✅ 能准确点击百度百科链接
4. ✅ 能智能滚动并找到信用代码
5. ✅ 能准确提取 18 位信用代码

### 示例返回

```json
{
  "creditCode": "91330000MA28A6FU6N",
  "organizationName": "数字浙江科技有限公司"
}
```

---

## 📊 模型分工详解

### Midscene 任务分类

Midscene 将任务分为 3 大类：

#### 1. Planning（规划任务）
**用途**: 将复杂指令拆解为步骤序列

**示例输入**:
```
在百度搜索数字浙江并点击百度百科
```

**期望输出** (JSON):
```json
{
  "tasks": [
    {"type": "Input", "locate": "搜索框", "value": "数字浙江"},
    {"type": "Tap", "locate": "百度一下"},
    {"type": "Tap", "locate": "百度百科链接"}
  ]
}
```

**使用模型**: Qwen2-VL-72B-Instruct（支持 JSON）

#### 2. VQA（视觉问答任务）
**用途**: 回答页面相关问题

**示例输入**:
```
判断当前页面是否显示了"统一社会信用代码"
```

**期望输出**: `true` 或 `false` 或具体答案

**使用模型**: QVQ-72B-Preview（推理能力强）

#### 3. Grounding（元素定位任务）
**用途**: 在页面中定位元素

**示例输入**:
```
定位"百度一下"按钮
```

**期望输出**: 元素坐标和边界框

**使用模型**: QVQ-72B-Preview（视觉定位准确）

---

## 💡 为什么这个配置最优？

### 对比其他方案

| 方案 | Planning | VQA | Grounding | 优势 | 劣势 |
|------|---------|-----|-----------|------|------|
| **纯 QVQ** ❌ | QVQ | QVQ | QVQ | 推理强 | JSON 解析失败 |
| **纯 Qwen2-VL** ⚠️ | Qwen2-VL | Qwen2-VL | Qwen2-VL | JSON 支持好 | 推理能力弱 |
| **混合配置** ✅ | Qwen2-VL | QVQ | QVQ | 结合优势 | 无 |
| **Claude** ⚠️ | Claude | Claude | Claude | 能力最强 | 代理不兼容 |
| **GPT-4o** ⚠️ | GPT-4o | GPT-4o | GPT-4o | 官方支持 | 成本高 |

### 混合配置的优势

1. **完美兼容性**
   - ✅ Planning 用 Qwen2-VL，支持 JSON
   - ✅ VQA/Grounding 用 QVQ，推理能力强

2. **成本优化**
   - 💰 Planning 任务调用次数少，使用便宜的 Qwen2-VL
   - 💰 VQA/Grounding 调用频繁，QVQ 性价比高

3. **性能最优**
   - 🎯 JSON 任务用擅长 JSON 的模型
   - 👁️ 视觉任务用擅长视觉推理的模型

---

## 🔄 如何调整配置

### 如果想使用纯 Qwen2-VL（稳定但推理弱）

编辑 `.env`:

```bash
MIDSCENE_MODEL_NAME=Qwen/Qwen2-VL-72B-Instruct
MIDSCENE_PLANNING_MODEL_NAME=Qwen/Qwen2-VL-72B-Instruct
MIDSCENE_VQA_MODEL_NAME=Qwen/Qwen2-VL-72B-Instruct
MIDSCENE_GROUNDING_MODEL_NAME=Qwen/Qwen2-VL-72B-Instruct
```

重启服务：
```bash
pkill -f "pnpm run demo" && cd apps/playground && __SERVER_URL__=http://localhost:5870 pnpm run demo
```

### 如果想使用纯 QVQ（推理强但需分步）

编辑 `.env`:

```bash
MIDSCENE_MODEL_NAME=Qwen/QVQ-72B-Preview
MIDSCENE_VQA_MODEL_NAME=Qwen/QVQ-72B-Preview
MIDSCENE_GROUNDING_MODEL_NAME=Qwen/QVQ-72B-Preview
# Planning 仍需 Qwen2-VL，否则 JSON 解析失败
MIDSCENE_PLANNING_MODEL_NAME=Qwen/Qwen2-VL-72B-Instruct
```

**注意**: 即使主模型用 QVQ，Planning 也必须用 Qwen2-VL

---

## 📚 相关文档

- 📄 `QVQ模型兼容性问题与解决方案.md` - QVQ 模型问题详解
- 📄 `Anthropic配置问题和解决方案.md` - Claude 配置问题
- 📄 `模型选择指南.md` - 视觉 vs 非视觉模型
- 📄 `Playground手动测试指南.md` - 测试指令大全
- 📄 `.env` - 当前配置文件

---

## ✅ 总结

### 问题与解决

| 问题 | 原因 | 解决方案 |
|------|------|---------|
| JSON 解析错误 | QVQ 输出文本而不是 JSON | Planning 用 Qwen2-VL |
| 找不到"百度一下" | Qwen3-VL 识别能力弱 | Grounding 用 QVQ |
| Claude 代理失败 | Anthropic SDK 不兼容 | 使用 Qwen 系列 |

### 当前最佳配置

✅ **混合配置**: Qwen2-VL (规划) + QVQ-72B-Preview (视觉)

**优势**:
- 支持复杂指令
- 强大的视觉推理
- 成本优化
- 完美兼容性

现在可以开始测试了！🚀

访问 http://localhost:3000 开始你的测试吧！
